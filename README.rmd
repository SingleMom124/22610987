---
output:
  md_document:
    variant: markdown_github
---

# Question 1:

This project explores baby naming trends in the United States, examining data from 1910 to 2014. The analysis focuses on identifying patterns influenced by cultural and societal factors, such as popular media and historical events.

```{r message=FALSE, warning=FALSE, include=FALSE}

rm(list = ls())
gc() 

library(tidyverse)
library(readr)

list.files('Question1/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))

baby_names <- read_rds("Question1/data/Baby_Names_By_US_State.rds")
charts <- read_rds("Question1/data/charts.rds")
hbo_titles <- read_rds("Question1/data/HBO_titles.rds")
hbo_credits <- read_rds("Question1/data/HBO_credits.rds")

```

First, using my "spearman_corr" function, I calculate the Spearman correlation between the popularity rankings of the 25 most common names for a specified gender across consecutive Olympic years. It processes the input data to aggregate name counts by year and gender. Two nested functions are utilized: popular_names identifies the top 25 names for a given year and gender, while spearman_cor computes the Spearman correlation coefficient between the ranks of names from two different years, ensuring all names are standardized across years. The results are stored in a dataframe plot_data, which contains the year, gender, and Spearman correlation coefficient for each pair of years analyzed.

Then using my "ts_corr_plotter", I creates three separate time-series plots to visualize the Spearman correlation coefficients of name popularity trends over Olympic years for boys, girls, and the average of both genders. It utilizes input datasets male_data and female_data, each containing Spearman correlation data computed by the spearman_corr function. Within the function, three plots are generated: corr_plot_boys for boys' names, corr_plot_girls for girls' names, and corr_plot for the average correlation across genders.

```{r}

# Getting the Spearman correlations in the form of plot data using my spearman_plot function...

plot_data_M <- spearman_corr(baby_names, gender = "M")
plot_data_F <- spearman_corr(baby_names, gender = "F")

# ... and plotting said data using my time series correlation plotter function.

plots <- ts_corr_plotter(plot_data_M, plot_data_F)
plots

```

What we see here is a decline in the persistence of naming trends for boys names since the 1990s, while girls' names have demonstrated greater resilience over time. However, overall, we do see a decline in the persistence of naming trends since the 1990s, confirming the agencies suspicion.

Next I look at what other cultural influences may be impacting on these trends, such as actor names. I do this by plotting the the 5 most popular names throughout the entire data set and their trends over time using my "name_plotter_function" which analyzes and visualizes trends in the top 5 most popular names over time, focusing on either male or female names based on the gender parameter. It aggregates name counts from the input data set by Year, Gender, and Name, identifies the top names by total count, filters the data accordingly, and creates a line plot

```{r}

# Plotting the top 5 persistently popular names per gender throughout the years

top_male_names <- name_plotter(baby_names, gender = "M")
top_male_names

top_female_names <- name_plotter(baby_names, gender = "F")
top_female_names

```

I then set out to determine how actor names may be correlated to baby names. Using my "names_reg" function, I perform panel data regressions to analyze the relationship between name popularity (measured by Count) and various predictors (tmdb_popularity, imdb_score, and Top_5_actor) within the context of media data (credits and movies). It does this by summarizing national baby name data (baby_names) by year, gender, and name. Then, it identifies the top 5 most popular names based on total count. After joining media data (credits and movies), it creates a binary variable (Top_5_actor) to mark whether an actor's first name matches one of the top 5 names. Panel data regressions are then conducted with three models: pooled, random effects, and fixed effects I then ran regressions on a names count.

Here I include the Breusch-Pagan and Hausman tests as I could not get them to knit In the pdf.

```{r echo=FALSE, message=FALSE, warning=FALSE}

# Using the 'plm' package to run regressions on the panel data, which I employ using my names_reg function

actor_names_M <- names_reg_test(baby_names, hbo_credits, hbo_titles, gender = "M")
actor_names_M

actor_names_F <- names_reg_test(baby_names, hbo_credits, hbo_titles, gender = "F")
actor_names_F

```

For both male and female names the Breusch-Pagan tests suggest that pooled OLS is insufficient. Where they differ is the model type. For the male names the Hausman test has a small p-value, indicating that the fixed effects (FE) model better represents the effect of an actor with a popular name being in a title on name counts for that year. For the female names the Hausman test has a larger p-value, indicating that the random effects (RE) model better represents the effect of an actor with a popular name being in a title on name counts for that year. 

However both suggest that media such as movies and television, significantly impact naming conventions. Analysis reveals correlations between popular actor names and increased occurrences of those names in baby naming trends.

# Question 2:

This project explores the musical evolution of Coldplay and Metallica through detailed analysis of their discographies using data from Spotify and Billboard. The analysis focuses on their studio recordings to maintain consistency and relevance in comparisons.

```{r include=FALSE}
rm(list = ls()) 
gc() 

library(readr)
library(tidyverse)

list.files('Question2/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))

coldplay <- read_csv("Question2/data/Coldplay.csv")
metallica <- read_csv("Question2/data/metallica.csv")
spotify <- read_rds("Question2/data/Broader_Spotify_Info.rds")
billboard_100 <- read_rds("Question2/data/charts.rds")

```

First I set out to Isolate each bands studio recordings using my "studio_filter" function which checks if the duration column is present; if so, it converts it from seconds to milliseconds by creating a new column (duration_ms). Next, it verifies if the column name album_name exists; if found, it renames it to album for consistency. Following these adjustments, the function identifies non-studio recordings by filtering out albums and songs that contain keywords like "Live," "Demo," "Edition," "Deluxe," "Remastered," "Motion," "Progress," or "Edit." The resulting dataset (band_studio) includes only studio recordings, excluding alternative versions or live performances.

I then use my "box_plotter" function to start off with the plot the question recommends for each band. 

```{r}
# Using functions to filter out all non-studio songs...

coldplay_studio <- studio_filter(coldplay)
metallica_studio <- studio_filter(metallica)

c_plot <- box_plotter(coldplay_studio, "popularity", title = "Popularity by album (Coldplay)")
m_plot <- box_plotter(metallica_studio, "popularity", title = "Popularity by album (Metallica)")
c_plot
m_plot
```

Box and whisker plots show that Coldplay has more consistent popularity levels across their albums, while Metallica's popularity varies significantly, with notable peaks for certain albums.

I then proceed to evaluate the bands attributes in relation to one another, and in relation to the billboard100. I do this with my lengthy "band_attributes" function. First, it subsets and combines data for each band (data1, data2, data3) by selecting attributes such as tempo, energy, valence, danceability, and duration from their respective datasets. Each subset is annotated with the band's name (band_name1, band_name2, band_name3). Here band 3 is the billboard100. Next, it converts the release dates to release years and calculates the average attributes (avg_tempo, avg_energy, avg_valence, avg_danceability, avg_duration_ms) by band and release year using summarise.

Finally, it creates five separate line plots, each plotting one of the average attributes (avg_tempo, avg_energy, avg_valence, avg_danceability, avg_duration_ms) over the release years for Metallica, Coldplay, and the billboard100.

```{r}
# First wrangling the Spotify and billboard data a little bit and joining them...

billboard_100 <- billboard_100 %>% 
    rename(name = song)

mainstream_music <- inner_join(spotify, billboard_100, by = c("name", "artist"))
mainstream_music <- mainstream_music %>% 
    rename(release_date = date)

# .. then feeding it to my attributes plotting function

attributes <- band_attributes(metallica_studio, coldplay_studio, mainstream_music, band_name1 = "Metallica", band_name2 = "Coldplay", band_name3 = "Billboard100")
print(attributes)
```

To further examine each bands attributes I plot heatmaps using my "heat_mapper" function which creates a heatmap visualizing correlations between various musical attributes such as duration, danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, and tempo. It does this by first subsetting the provided data (data) to include only the relevant attributes (duration_ms, danceability, energy, loudness, speechiness, acousticness, instrumentalness, liveness, valence, tempo). Following this it calculates the correlation matrix (band_cormat) across these attributes which is then converted into a data frame to facilitate plotting.

```{r}
m_heatmap <- heat_mapper(metallica_studio, title = "Heatmap for Metallica Songs")
m_heatmap
c_heatmap <- heat_mapper(coldplay_studio, title = "Heatmap for Coldplay Songs")
c_heatmap
```

# Question 3:

Project focuses on international aid efforts amidst the Russia-Ukraine conflict, specifically analyzing which countries are actively contributing to Ukraine's defense and humanitarian needs. Highlighting both leading contributors and areas of criticism, the segment aims to provide viewers with insights into global responses and their implications for the ongoing conflict.

```{r message=FALSE, warning=FALSE, include=FALSE}

rm(list = ls()) 
gc()

library(tidyverse)
library(readr)

list.files('Question3/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))

alloc <- read_csv("Question3/data/Financial Allocations.csv")
commit <- read_csv("Question3/data/Financial Commitments.csv")

```

## Data Visualisation:

Looking at the scale effect of each countries commitments and allocations as a proportion of their total GDP. It is important to note here that Estonia's allocation was more than 75% of its GDP and Malta's more than 30%. This seems unlikely and is verifiably false. For example, a quick Google shows that Estonia's allocations as of 2024 amount to 1.4% of its GDP. This is likely due to measurement error and so these two countries have been removed from the data.

```{r echo=FALSE, message=FALSE, warning=FALSE}

# Just a small bit of wrangling...

# ... by joining the data sets by "country" and "EU member" columns so that I only have to work with one data set...

data <- inner_join(alloc, commit, by = c("Country", "EU member"))

# ... and then filtering out countries who are not EU Members

data <- data %>% 
    filter(`EU member` == 1) %>%
    mutate(Allocations_GDP_Percent = (`Total bilateral allocations($ billion)` / `GDP in 2021($ billion)`) * 100) %>% 
    mutate(Commitments_GDP_Percent = (`Total bilateral commitments($ billion)` / `GDP in 2021($ billion)`) * 100)

plot <- ggplot(data, aes(x = Country, 
                         y = Allocations_GDP_Percent)) +
        geom_bar(stat = "identity", 
                 fill = "navy") +
        labs(title = "Total Allocations as a Proportion of GDP",
             x = "Country",
             y = "Percentage of GDP") +
        theme_minimal() +
        theme(axis.text.x = element_text(size = 7, angle = 45, hjust = 1)) +
        theme(panel.border = element_rect(color = "black", fill = NA, size = 1))
plot

```

I then seek to compare each EU members allocation to what it committed to allocate using my "double_bar_plotter" function which converts the input data (data) from wide to long format (data_long) using pivot_longer. This transformation reshapes the data so that each row represents a combination of a country (Country) and a category (Compare, which can be either "Allocations_GDP_Percent" or "Commitments_GDP_Percent"), and the corresponding value (Percent) is assigned to each category. It then creates a double bar plot to compare two categories (Allocations_GDP_Percent and Commitments_GDP_Percent) across different countries.

```{r echo=FALSE, message=FALSE, warning=FALSE}

# Filtering out Estonia and Malta...

data <- data %>%
    filter(!Country %in% c("Estonia", "Malta"))

# Now plotting it using my "double_bar_plotter" function...

compare_plot <- double_bar_plotter(data)
compare_plot

```

I also use the filtered data to plot how many EU members allocated as much they committed versus how many fell short. I do this with my "allocation_proportions" function which calculates and visualizes the percentage of EU members that met their commitments compared to those that did not, based on data provided. The function first filters the input data (data) to select rows where the "Commitments_GDP_Percent" is less than or equal to "Allocations_GDP_Percent", indicating actions that were followed through. It then calculates the proportions of these actions relative to the total number of observations in data, after which the data is plotted.

```{r echo=FALSE, message=FALSE, warning=FALSE}

# Plot this using my "allocation_proportions" function

proportions <- allocation_proportions(data)
proportions

```

... as well as which countries have the highest relative allocations using my "allocation_head" function which identifies and presents the top 5 countries with the largest relative allocations based on data provided.

```{r echo=FALSE, message=FALSE, warning=FALSE}

# Plot this using my "allocation_head" function...

allocation_head <- allocation_head(data)
allocation_head

```

Some main points to gather from this are that even though most EU members allocated at least as much aid to Ukraine as what they committed, 48% failed to meet their commitment. Additionally, it seems as though countries closer to the conflict have the highest allocations, these including mostly slavic nations and former USSR occupants.

# Question 4:

```{r message=FALSE, warning=FALSE, include=FALSE}

rm(list = ls()) 
gc()

library(tidyverse)
library(readr)

list.files('Question4/code/', full.names = T, recursive = T) %>% .[grepl('.R', .)] %>% as.list() %>% walk(~source(.))

Winter <- read_rds("Question4/data/winter.rds")
Summer <- read_rds("Question4/data/summer.rds")
colnames(Summer)[6] <- "Code"
colnames(Winter)[6] <- "Code"
GDP <- read_rds("Question4/data/GDP.rds")

```

Looking at how India cumulatively fared in past Olympic events and comparing this to Brazil, Pakistan, and South Africa during years in which they all competed. I do this using my "country_comparison" function which function generates a bar plot comparing total medal counts across selected countries using medal_data and gdp_data.

```{r}
# Joining the summer Olympic and GDP data by country code

summer_gdp <- left_join(Summer, GDP, by = "Code")

# Using my "medal counter function"team_adjuster" function

summer_medals <- team_adjuster(summer_gdp)

# Now plotting this data using my "country_comparison" function, comparing India to similar and emerging economies...

india_compare <- country_comparison_bar(summer_medals, GDP, "India")
india_compare
```

The plot below shows the three most consistently dominant countries, in both the summer and the winter Olympics are France, the United Kingdom, and the United States, all of which see medal counts higher than average across the board

```{r}
# A small bit of wrangling, bindin the summer and winter Olympics sets together and join GDP to this new data set by the "Code" column

olympics <- rbind(Summer, Winter)
olympics_gdp <- left_join(olympics, GDP, by = "Code")

# Using the my "team_adjuster" function to account for duplicate medals...

team_adjusted <- team_adjuster(olympics_gdp)

# ... and inseting the output in to my "high_performance" function

dominant_countries <- high_performance(team_adjusted)
dominant_countries
```

Countries who manage to punch above their weight include Finland, France, Hungary, and Italy. We define this as a countries ability to win more medals than the average fairly consistently as well as by the number of athletes they have competing in a given year.

```{r}

# Plotted using my "above_weight" function

no_odds <- above_weight(summer_gdp, summer_medals)
no_odds
```

Now plotting which countries have the most medals per athlete. The United States takes the cake by far here.

```{r}

# Plotted using my "all_time_best" function

best_athletes <- all_time_best(olympics_gdp)
best_athletes
```

# Question 5:

I could not get this question to work.

```{r message=FALSE, warning=FALSE, include=FALSE}

rm(list = ls()) 
gc()

library(dbbasic)
library(DBI)
```

```{r}
usethis::edit_r_environ()
```

```{r}
library(dbbasic)
conn <- db_connect(db = "datascience")
```




